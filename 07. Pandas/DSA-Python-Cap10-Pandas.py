#!/usr/bin/env python
# coding: utf-8

# # <font color='blue'>Data Science Academy</font>
# 
# ## <font color='blue'>Fundamentos de Linguagem Python Para An√°lise de Dados e Data Science</font>
# 
# ## <font color='blue'>Manipula√ß√£o de Dados com Pandas</font>

# ![DSA](imagens/dsa_cap10.png)

# In[1]:


# Vers√£o da Linguagem Python
from platform import python_version
print('Vers√£o da Linguagem Python Usada Neste Jupyter Notebook:', python_version())


# Guia de Usu√°rio do Pandas:
# 
# https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide

# In[2]:


# Instala a vers√£o exata do pacote
get_ipython().system('pip install -q pandas==1.5.3')


# In[3]:


import pandas as pd


# In[4]:


pd.__version__


# ## Manipulando Dados em DataFrames do Pandas 

# In[5]:


# Cria um dicion√°rio
dados = {'Estado': ['Santa Catarina', 'Rio de Janeiro', 'Tocantins', 'Bahia', 'Minas Gerais'], 
         'Ano': [2004, 2005, 2006, 2007, 2008], 
         'Taxa Desemprego': [1.5, 1.7, 1.6, 2.4, 2.7]}


# In[6]:


print(dados)


# In[7]:


# Importa a fun√ß√£o DataFrame do Pandas
from pandas import DataFrame


# In[8]:


# Converte o dicion√°rio em um dataframe
df = DataFrame(dados)


# In[9]:


# Visualiza as 5 primeiras linhas
df.head()


# In[10]:


type(df)


# In[11]:


# Reorganizando as colunas
DataFrame(dados, columns = ['Estado', 'Taxa Desemprego', 'Ano'])


# In[12]:


# Criando outro dataframe com os mesmo dados anteriores mas adicionando uma coluna
df2 = DataFrame(dados, 
                columns = ['Estado', 'Taxa Desemprego', 'Taxa Crescimento', 'Ano'], 
                index = ['estado1', 'estado2', 'estado3', 'estado4', 'estado5'])


# In[13]:


df2


# In[14]:


df2.values


# In[15]:


df2.dtypes


# In[16]:


df2.columns


# In[17]:


# Imprimindo apenas uma coluna do Dataframe
df2['Estado']


# In[18]:


# Linguagem Python √© case sensitive
# df2['estado']


# In[19]:


# Imprimindo apenas duas colunas do Dataframe
df2[ ['Taxa Desemprego', 'Ano'] ]


# In[20]:


df2.index


# In[21]:


# Filtrando pelo √≠ndice
df2.filter(items = ['estado3'], axis = 0)


# ## Usando NumPy e Pandas Para Manipula√ß√£o de Dados

# In[22]:


df2.head()


# In[23]:


df2.dtypes


# In[24]:


# Resumo estat√≠stico do Dataframe
df2.describe()


# In[25]:


df2.isna()


# In[26]:


df2['Taxa Crescimento'].isna()


# In[27]:


# Importando o NumPy
import numpy as np


# In[28]:


# Usando o NumPy para alimentar uma das colunas do dataframe
df2['Taxa Crescimento'] = np.arange(5.)


# In[29]:


df2


# In[30]:


df2.dtypes


# In[31]:


df2['Taxa Crescimento'].isna()


# In[32]:


# Resumo estat√≠stico do Dataframe
df2.describe()


# ## Slicing de DataFrames do Pandas

# In[33]:


df2


# In[34]:


df2['estado2':'estado4']


# In[35]:


df2[ df2['Taxa Desemprego'] < 2 ]


# In[36]:


df2['Taxa Crescimento']


# In[37]:


df2[['Estado', 'Taxa Crescimento']]


# In[38]:


df2[['Estado', 'Taxa Crescimento', 'Ano']]


# ## Preenchendo Valores Ausentes em DataFrames do Pandas
# 
# A fun√ß√£o fillna() √© usada para preencher os valores ausentes. A fun√ß√£o oferece muitas op√ß√µes. Podemos usar um valor espec√≠fico, uma fun√ß√£o agregada (por exemplo, m√©dia) ou o valor anterior ou seguinte.
# 
# Para esse exemplo usaremos a moda, a estat√≠stica que representa o valor que aparece mais vezes em uma vari√°vel.

# In[39]:


# Primeiro importamos um dataset
dsa_df = pd.read_csv("dataset.csv")


# In[40]:


dsa_df.head(15)


# In[41]:


dsa_df.isna().sum()


# In[42]:


# Extra√≠mos a moda da coluna Quantity
moda = dsa_df['Quantidade'].value_counts().index[0]


# A moda em Estat√≠stica √© uma medida de tend√™ncia central que representa o valor mais frequente em um conjunto de dados. 
# 
# A moda √© especialmente √∫til quando queremos saber qual √© o valor mais comum ou popular em um conjunto de dados, seja em uma distribui√ß√£o unimodal (com apenas uma moda) ou em uma distribui√ß√£o bimodal (com duas modas).
# 
# No entanto, a moda pode n√£o ser t√£o representativa quanto outras medidas de tend√™ncia central, como a m√©dia e a mediana, especialmente em distribui√ß√µes assim√©tricas ou quando h√° valores extremos. Por essa raz√£o, √© importante analisar diferentes medidas de tend√™ncia central e usar a que melhor se adequa aos objetivos da an√°lise estat√≠stica.

# In[43]:


print(moda)


# In[44]:


# E por fim preenchemos os valores NA com a moda
dsa_df['Quantidade'].fillna(value = moda, inplace = True)


# In[45]:


dsa_df.isna().sum()


# ## Query (Consulta) de Dados no DataFrame do Pandas
# 
# Com o Pandas criamos dataframes, que s√£o essencialmente tabelas. Como tal, podemos fazer consultas, ou simplesmente queries. E para isso usamos o m√©todo query(). Veja o exemplo abaixo:

# In[46]:


dsa_df.head()


# In[47]:


# Checamos os valores m√≠nimo e m√°ximo da coluna Valor_Venda
dsa_df.Valor_Venda.describe()


# O intervalo de vendas (Valor_Venda) √© de 0.44 a 22638. Vamos fazer uma consulta e retornar todas as vendas dentro de um range de valores. Fazemos isso com a instru√ß√£o abaixo:

# In[48]:


# Geramos um novo dataframe apenas com o intervalo de vendas entre 229 e 10000
df2 = dsa_df.query('229 < Valor_Venda < 10000')


# In[49]:


# Ent√£o confirmamos os valores m√≠nimo e m√°ximo
df2.Valor_Venda.describe()


# In[50]:


# Geramos um novo dataframe apenas com os valores de venda acima da m√©dia
df3 = df2.query('Valor_Venda > 766')


# In[51]:


df3.head()


# Consulta executada com sucesso!

# ## Verificando a Ocorr√™ncia de Diversos Valores em Uma Coluna
# 
# Em nosso conjunto de dados de exemplo temos a coluna Quantidade que representa a quantidade de itens vendidos em cada uma das vendas. Imagine que precisamos saber em quais vendas foram vendidos 5, 7, 9 ou 11 itens. 
# 
# Como aplicar√≠amos esse tipo de filtro ao nosso dataframe?
# 
# F√°cil. O Pandas oferece o m√©todo isin() para checar diversos valores em uma coluna. Quem conhece Linguagem SQL j√° deve ter percebido que o m√©todo √© o mesmo que a cl√°usula IN em SQL. Vamos ao exemplo.

# In[52]:


dsa_df.shape


# In[53]:


# Ent√£o aplicamos o filtro
dsa_df[dsa_df['Quantidade'].isin([5,7,9,11])]


# Na instru√ß√£o acima estamos filtrando o dataframe chamado df, retornando todas as linhas onde a coluna Quantidade for igual aos valores 5, 7, 9 ou 11. Passamos uma lista de valores como argumento para o m√©todo isin().
# 
# Vamos deixar um pouquinho mais divertido. Se voc√™ executou a instru√ß√£o acima, percebeu que foram retornadas 2.128 linhas. E se quisermos retornar somente 10 linhas? √â s√≥ fatiar o resultado assim:

# In[54]:


# Shape
dsa_df[dsa_df['Quantidade'].isin([5,7,9,11])].shape


# In[55]:


dsa_df[dsa_df['Quantidade'].isin([5,7,9,11])][:10]


# O Pandas n√£o √© incr√≠vel? üòÅ

# ## Operadores L√≥gicos Para Manipula√ß√£o de Dados com Pandas
# 
# Os operadores l√≥gicos s√£o excelentes para filtrar dataframes e retornar exatamente os dados que precisamos para nosso trabalho. Para conhecer mais sobre as regras dos operadores l√≥gicos, acesse aqui:
# 
# https://pt.wikipedia.org/wiki/Operador_l%C3%B3gico

# Primeiro usaremos o operador l√≥gico AND para checar duas condi√ß√µes. Ser√£o retornados os registros quando as duas condi√ß√µes forem verdadeiras.

# In[56]:


# Filtrando as vendas que ocorreram para o segmento de Home Office e na regi√£o South
dsa_df[ (dsa_df.Segmento == 'Home Office') & (dsa_df.Regiao == 'South') ].head()


# Mas pode ser necess√°rio checar duas condi√ß√µes e retornar os registros se pelo menos uma for verdadeira. Nesse caso usamos o operador OR, conforme abaixo.

# In[57]:


# Filtrando as vendas que ocorreram para o segmento de Home Office ou regi√£o South
dsa_df[(dsa_df.Segmento == 'Home Office') | (dsa_df.Regiao == 'South')].tail()


# O operador de nega√ß√£o √© o contr√°rio do primeiro exemplo.

# In[58]:


# Filtrando as vendas que n√£o ocorreram para o segmento de Home Office e nem na regi√£o South
dsa_df[(dsa_df.Segmento != 'Home Office') & (dsa_df.Regiao != 'South')].sample(5)


# ## Agrupamento de Dados em DataFrames com Group By
# 
# A fun√ß√£o Pandas Groupby √© uma fun√ß√£o vers√°til e f√°cil de usar que ajuda a obter uma vis√£o geral dos dados. Isso torna mais f√°cil explorar o conjunto de dados e revelar os relacionamentos entre as vari√°veis.
# 
# O c√≥digo a seguir agrupar√° as linhas com base nas combina√ß√µes Segmento/Regiao/Valor_Venda e nos dar√° a taxa m√©dia de vendas de cada grupo.

# In[59]:


# Aplicamos o group by
dsa_df[['Segmento', 'Regiao', 'Valor_Venda']].groupby(['Segmento', 'Regiao']).mean()


# Na instru√ß√£o acima, primeiro filtramos os dados extraindo 3 colunas: ['Segmento','Regiao','Valor_Venda']. Na sequ√™ncia, agrupamos por duas colunas: ['Segmento','Regiao']. E ent√£o calculamos a m√©dia para a coluna que ficou foram do group by, nesse caso a coluna Sales.
# 
# O comportamento do group by com Pandas √© o mesmo observado na Linguagem SQL.

# ## Agrega√ß√£o M√∫ltipla com Group By
# 
# Vamos explorar mais a fun√ß√£o groupby() pois temos diversas op√ß√µes de sumariza√ß√£o dos dados de forma simples. No exemplo abaixo uniremos a fun√ß√£o groupby() com a fun√ß√£o agg() para realiza agrega√ß√£o m√∫ltipla.

# In[60]:


# Aplicamos o group by
dsa_df[['Segmento', 'Regiao', 'Valor_Venda']].groupby(['Segmento', 'Regiao']).agg(['mean', 'std', 'count'])


# Na instru√ß√£o acima, primeiro filtramos os dados extraindo 3 colunas: ['Segmento','Regiao','Valor_Venda']. Na sequ√™ncia, agrupamos por duas colunas: ['Segmento','Regiao']. E ent√£o agregamos os dados calculando a m√©dia, desvio padr√£o e contagem de elementos para a coluna que ficou fora do group by, nesse caso a coluna Valor_Venda.
# 
# A fun√ß√£o agg() recebe como argumento uma lista de fun√ß√µes para agrega√ß√£o.

# ## Filtrando DataFrame do Pandas com Base em Strings
# 
# O Pandas oferece diversas fun√ß√µes para manipula√ß√£o de strings. Come√ßaremos com o filtros de strings com base nas letras iniciais e finais.

# In[61]:


dsa_df.head()


# In[62]:


# Filtramos o dataframe pela coluna Segmento com valores que iniciam com as letras 'Con'
dsa_df[dsa_df.Segmento.str.startswith('Con')].head()


# In[63]:


dsa_df.Segmento.value_counts()


# In[64]:


# Filtramos o dataframe pela coluna Segmento com valores que terminam com as letras 'mer'
dsa_df[dsa_df.Segmento.str.endswith('mer')].head()


# As fun√ß√µes startswith() e endswith() s√£o muito √∫teis quando for necess√°rio filtrar strings por caracteres que apare√ßam no come√ßo e/ou final.

# ## Split de Strings em DataFrames do Pandas
# 
# Com Pandas podemos realizar diversas tarefas de split de strings dividindo uma coluna ou extraindo elementos do nosso interesse. Vamos ao exemplo!

# In[65]:


dsa_df.head()


# In[66]:


dsa_df['ID_Pedido'].head()


# Este √© o formato dos dados da coluna "ID_Pedido":
# 
# - CA-2016-152156
# - US-2015-108966
# 
# Temos o pa√≠s, o ano e o id do pedido. Vamos dividir essa coluna e extrair o ano para gravar em uma nova coluna:

# In[67]:


# Split da coluna pelo caracter '-'
dsa_df['ID_Pedido'].str.split('-')


# Observe que o resultado s√£o as listas em Python. Para extrair o ano precisamos especificar o √≠ndice da posi√ß√£o que queremos extrair (em nosso caso a posi√ß√£o 2, logo, √≠ndice 1 em Python):

# In[68]:


dsa_df['ID_Pedido'].str.split('-').str[1].head()


# In[69]:


# Fazemos o split da coluna e extra√≠mos o item na posi√ß√£o 2 (√≠ndice 1)
dsa_df['Ano'] = dsa_df['ID_Pedido'].str.split('-').str[1]


# In[70]:


# Ent√£o conferimos a nova coluna criada
dsa_df.head()


# ## Strip de Strings em DataFrames do Pandas
# 
# Cuidado para n√£o confundir. Vimos o Split e agora veremos o Strip. S√£o fun√ß√µes diferentes.
# 
# O Split divide a string. O Strip remove caracteres da string. Veja os exemplos.

# In[71]:


dsa_df.head(3)


# In[72]:


dsa_df['Data_Pedido'].head(3)


# A coluna 'Data_Pedido' √© a data de envio do produto no formato YYYY-MM-DD. Imagine que seja necess√°rio deixar o ano apenas com 2 d√≠gitos sem alterar o tipo da vari√°vel. Fazemos isso com a fun√ß√£o lstrip(), ou seja, left strip.

# In[73]:


# Vamos remover os d√≠gitos 2 e 0 √† esquerda do valor da vari√°vel 'Data_Pedido'
dsa_df['Data_Pedido'].str.lstrip('20')


# Como n√£o usamos o inplace = True a mudan√ßa √© somente na mem√≥ria e n√£o altera o dataframe. Podemos usar ainda as fun√ß√µes rstrip() e strip() com diferentes varia√ß√µes de strip de strings.

# In[74]:


dsa_df['Data_Pedido'].head(3)


# ## Replace de Strings em DataFrames do Pandas
# 
# Se for necess√°rio substituir caracteres dentro de uma string o Pandas oferece uma fun√ß√£o para isso tamb√©m.
# 
# Por exemplo, vamos substituir 2 caracteres em uma das colunas.

# In[75]:


dsa_df.head()


# In[76]:


# Substitu√≠mos os caracteres CG por AX na coluna 'ID_Cliente'
dsa_df['ID_Cliente'] = dsa_df['ID_Cliente'].str.replace('CG', 'AX')


# In[77]:


dsa_df.head()


# E pronto. F√°cil assim.

# ## Combina√ß√£o de Strings em DataFrames do Pandas
# 
# A fun√ß√£o cat() pode ser usada para concatenar strings em um dataframe do Pandas.
# 
# Vamos criar uma nova coluna concatenando as colunas ‚ÄúID_Pedido‚Äù e ‚ÄúSegmento‚Äù com o separador ‚Äú-‚Äù.

# In[78]:


dsa_df.head()


# In[79]:


# Concatenando strings
dsa_df['Pedido_Segmento'] = dsa_df['ID_Pedido'].str.cat(dsa_df['Segmento'], sep = '-')


# In[80]:


dsa_df.head()


# ## Constru√ß√£o de Gr√°ficos a Partir de DataFrames do Pandas
# 
# Vimos at√© aqui diversas funcionalidades do Pandas que tornam o processo de manipula√ß√£o de dados realmente simples. E para concluir este cap√≠tulo vamos estudar as op√ß√µes que o Pandas oferece para cria√ß√£o de gr√°ficos diretamente a partir de dataframes, sem a necessidade de usar qualquer outra biblioteca. 
# 
# Acompanhe os exemplos.

# In[81]:


# Instala a vers√£o exata do Scikit-learn
get_ipython().system('pip install -q scikit-learn==1.2.1')


# In[82]:


import sklearn
sklearn.__version__


# In[83]:


# Vamos come√ßar importando o dataset iris do Scikit-learn
from sklearn.datasets import load_iris
data = load_iris()


# In[84]:


# E ent√£o carregamos o dataset iris como dataframe do Pandas
import pandas as pd
df = pd.DataFrame(data['data'], columns = data['feature_names'])
df['species'] = data['target']
df.head()


# In[85]:


# Para criar um gr√°fico de linhas com todas as vari√°veis do dataframe, basta fazer isso:
df.plot()


# In[86]:


# Que tal um scatter plot com duas vari√°veis? 
df.plot.scatter(x = 'sepal length (cm)', y = 'sepal width (cm)')


# In[87]:


# E mesmo gr√°ficos mais complexos, como um gr√°fico de √°rea, pode ser criado:
columns = ['sepal length (cm)', 'petal length (cm)', 'petal width (cm)', 'sepal width (cm)']
df[columns].plot.area()


# In[88]:


# Calculamos a m√©dia das colunas agrupando pela coluna species e criamos um gr√°fico de barras com o resultado
df.groupby('species').mean().plot.bar()


# In[89]:


# Ou ent√£o, fazemos a contagem de classes da coluna species e plotamos em um gr√°fico de pizza
df.groupby('species').count().plot.pie(y = 'sepal length (cm)')


# A lista de possibilidades √© imensa. Aqui tem muitos outros exemplos:
# 
# https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html
# 

# In[90]:


# Gr√°fico KDE (Kernel Density Function) para cada vari√°vel do dataframe
df.plot.kde(subplots = True, figsize = (8,8))


# In[91]:


# Boxplot de cada vari√°vel num√©rica
columns = ['sepal length (cm)', 'petal length (cm)', 'petal width (cm)', 'sepal width (cm)']
df[columns].plot.box(figsize = (8,8))


# O Pandas √© uma verdadeira caixa de ferramentas para manipula√ß√£o de dados em Python.

# # Fim

# ### Obrigado
# 
# ### Visite o Blog da Data Science Academy - <a href="http://blog.dsacademy.com.br">Blog DSA</a>
